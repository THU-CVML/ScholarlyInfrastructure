{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nbscholar 大牛学者\n",
    "\n",
    "> nbscholar (new-big scholar, 大牛学者) is a extension for better NoteBook development, extending fastai's `nbdev` libary. It is designed to assist you become a New-Big (a.k.a. 牛逼 or awesome) scholar one day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp nbscholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.script import call_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "functions = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "子模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "def nbscholar_submodules(mode:str=\"to_ssh\", *args, **kwargs):\n",
    "    if mode == \"to_ssh\":\n",
    "        nbscholar_submodules_to_ssh(*args, **kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {mode}\")\n",
    "functions.append(nbscholar_submodules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import re\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from scholarly_infrastructure.logging.nucleus import logger\n",
    "from fastcore.script import call_parse\n",
    "\n",
    "@call_parse\n",
    "def nbscholar_submodules_to_ssh(path: str = \".\"):\n",
    "    \"\"\"\n",
    "    Convert all HTTPS submodule URLs in `.gitmodules` to SSH URLs (e.g. https://github.com/user/repo.git → git@github.com:user/repo.git)\n",
    "    \"\"\"\n",
    "\n",
    "    gitmodules = Path(path) / \".gitmodules\"\n",
    "    if not gitmodules.exists():\n",
    "        logger.error(\"❌ 未找到 .gitmodules 文件，请在含有子模块的项目根目录运行此函数。\")\n",
    "        raise FileNotFoundError(\".gitmodules not found\")\n",
    "\n",
    "    content = gitmodules.read_text(encoding=\"utf-8\")\n",
    "\n",
    "    # 匹配 https://github.com/user/repo(.git)\n",
    "    pattern = re.compile(r\"https://([^/]+)/([^/]+)/([^/\\n]+)(\\.git)?\")\n",
    "\n",
    "    changed = False\n",
    "\n",
    "    def https_to_ssh(match):\n",
    "        nonlocal changed\n",
    "        host, user, repo, dotgit = match.groups()\n",
    "        ssh_url = f\"git@{host}:{user}/{repo}.git\"\n",
    "        logger.info(f\"🔁 转换: https://{host}/{user}/{repo} → {ssh_url}\")\n",
    "        changed = True\n",
    "        return ssh_url\n",
    "\n",
    "    new_content = pattern.sub(https_to_ssh, content)\n",
    "\n",
    "    if changed:\n",
    "        gitmodules.write_text(new_content, encoding=\"utf-8\")\n",
    "        logger.success(\"✅ 已更新 .gitmodules 文件中的 URL。\")\n",
    "\n",
    "        # 同步子模块配置\n",
    "        res = subprocess.run([\"git\", \"submodule\", \"sync\", \"--recursive\"])\n",
    "        if res.returncode == 0:\n",
    "            logger.success(\"✅ 已执行 `git submodule sync --recursive`。\")\n",
    "        else:\n",
    "            logger.warning(\"⚠️ `git submodule sync` 执行失败，请手动检查。\")\n",
    "    else:\n",
    "        logger.info(\"ℹ️ 没有发现 HTTPS 格式的子模块 URL，无需修改。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## nbscholar_docs\n",
    "\n",
    "alternative to nbdev_docs\n",
    "\n",
    "https://github.com/AnswerDotAI/nbdev/issues/1464\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nbscholar_license\n",
    "\n",
    "use google addlicense to add license to all files in the repo, while ignoring gitignore and gitmodules.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nbscholar_export\n",
    "\n",
    "alternative to nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import configparser\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_settings_ini(directory, item=\"nbs_path\", track=\"DEFAULT\", ini_name='settings.ini'):\n",
    "    config = configparser.ConfigParser()\n",
    "    # 逐级向上查找，直到找到第一个包含 settings.ini 的目录\n",
    "    current = directory\n",
    "    while True:\n",
    "        settings_path = os.path.join(current, ini_name)\n",
    "        if os.path.exists(settings_path):\n",
    "            break\n",
    "        parent = os.path.dirname(current)\n",
    "        if parent == current:  # 已到达根目录\n",
    "            raise FileNotFoundError(f\"Could not find {ini_name} in any parent of {directory}\")\n",
    "        current = parent\n",
    "\n",
    "    config.read(settings_path)\n",
    "    assert track in config, f\"Could not find {track} in {settings_path}\"\n",
    "    assert item in config[track], f\"Could not find {item} in {settings_path}\"\n",
    "    return config[track][item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import subprocess\n",
    "import os\n",
    "from scholarly_infrastructure.logging.nucleus import logger\n",
    "@call_parse\n",
    "def nbscholar_export(path:str = \".\"):\n",
    "    res = os.system(\"nbdev_export\")\n",
    "    if res!= 0:\n",
    "        raise Exception(\"nbdev_export failed\")\n",
    "    # 读取 settings.ini 的 lib_path\n",
    "    lib_path = read_settings_ini(path, item=\"lib_path\")\n",
    "\n",
    "    # MKINIT 生成 __init__.py\n",
    "    # res = os.system(f\"mkinit {lib_name} -w --lazy_loader --recursive --relative\")\n",
    "    res = os.system(f\"mkinit {lib_path} -w --lazy_loader_typed --recursive --relative\")\n",
    "    if res!= 0:\n",
    "        # raise Exception(\"mkinit failed\")\n",
    "        logger.warning(\"mkinit failed\")\n",
    "    \n",
    "    # RUFF 格式化\n",
    "    res = os.system(f\"ruff format {lib_path}\")\n",
    "    if res!= 0:\n",
    "        logger.warning(\"ruff format failed\")\n",
    "functions.append(nbscholar_export)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nbscholar_translate\n",
    "\n",
    "https://github.com/AnswerDotAI/nbdev/issues/1429"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nbscholar_license\n",
    "\n",
    "https://github.com/AnswerDotAI/nbdev/issues/1475"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nbscholar_separate\n",
    "\n",
    "https://github.com/AnswerDotAI/nbdev/issues/1468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import nbformat\n",
    "import re\n",
    "from nbformat.notebooknode import NotebookNode, from_dict\n",
    "from scholarly_infrastructure import default_on_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "read_settings_ini_none = default_on_exception(read_settings_ini, default_value=None)\n",
    "\n",
    "\n",
    "def guess_notebooks_path(directory=\".\"):\n",
    "    if isinstance(directory, Path):\n",
    "        directory = directory.as_posix()\n",
    "    # 读取 setting.ini 的 nbs_path， 如果有的话，没有就返回None\n",
    "    return read_settings_ini_none(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholarly_infrastructure.help import runs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebooks\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 创建一个临时的 settings.ini 文件进行测试\n",
    "with open(runs_path/\"settings.ini\", \"w\") as f:\n",
    "    f.write(\"[DEFAULT]\\nnbs_path=notebooks\")\n",
    "\n",
    "# 测试 guess_notebooks_path 函数\n",
    "print(guess_notebooks_path(runs_path))  # 应该输出 'notebooks'\n",
    "\n",
    "# 删除临时的 settings.ini 文件\n",
    "os.remove(runs_path/\"settings.ini\")\n",
    "\n",
    "# 测试 settings.ini 文件不存在的情况\n",
    "print(guess_notebooks_path(runs_path))  # 应该输出 None\n",
    "\n",
    "# 创建一个不包含 nbs_path 的 settings.ini 文件进行测试\n",
    "with open(runs_path/\"settings.ini\", \"w\") as f:\n",
    "    f.write(\"[DEFAULT]\\nother_key=other_value\")\n",
    "\n",
    "# 测试 guess_notebooks_path 函数\n",
    "print(guess_notebooks_path(runs_path))  # 应该输出 None\n",
    "\n",
    "# 删除临时的 settings.ini 文件\n",
    "os.remove(runs_path/\"settings.ini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def split_import_and_code_cells(notebook, inplace=True):\n",
    "    \"\"\"\n",
    "    Process a Jupyter Notebook file, splitting cells with both import and non-import lines into two cells.\n",
    "    The first new cell will contain only import statements, and the second will contain the rest of the code.\n",
    "    \"\"\"\n",
    "    notebook = notebook if inplace else deepcopy(notebook)\n",
    "    \n",
    "    new_cells = []\n",
    "\n",
    "    for cell in notebook['cells']:\n",
    "        if cell['cell_type'] == 'code':\n",
    "            # Split the lines in the cell\n",
    "            lines = cell['source'].splitlines()\n",
    "\n",
    "            # Extract leading blank lines or lines starting with \"#|\"\n",
    "            leading_lines = []\n",
    "            while lines and (lines[0].strip() == \"\" or lines[0].startswith(\"#|\")):\n",
    "                leading_lines.append(lines.pop(0))\n",
    "\n",
    "            # Separate import statements and other code lines\n",
    "            import_lines = [line for line in lines if re.match(r\"^\\s*import\\b|^\\s*from\\b\", line)]\n",
    "            other_lines = [line for line in lines if line not in import_lines]\n",
    "\n",
    "            if import_lines and other_lines:\n",
    "                # Add the leading lines to the import cell\n",
    "                \n",
    "                new_cells.append(from_dict(cell | {\n",
    "                    \"cell_type\": \"code\",\n",
    "                    \"metadata\": {},\n",
    "                    \"source\": \"\\n\".join(leading_lines + import_lines), \n",
    "                    \"outputs\": []\n",
    "                }))\n",
    "                # Add the leading lines to the other code cell\n",
    "                new_cells.append(from_dict(cell | {\n",
    "                    \"cell_type\": \"code\",\n",
    "                    \"metadata\": {},\n",
    "                    \"source\": \"\\n\".join(leading_lines + other_lines),\n",
    "                    \"outputs\": cell['outputs']\n",
    "                }))\n",
    "            else:\n",
    "                # If no split is needed, retain the original cell\n",
    "                new_cells.append(cell)\n",
    "        else:\n",
    "            # Retain non-code cells as is\n",
    "            new_cells.append(cell)\n",
    "\n",
    "    # Update the notebook with the modified cells\n",
    "    notebook['cells'] = new_cells\n",
    "    return notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def operate_on_notebook_in(input_path, output_path=None, operation=split_import_and_code_cells):\n",
    "    if output_path is None:\n",
    "        output_path = input_path\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        notebook = nbformat.read(f, as_version=4)\n",
    "    notebook = operation(notebook)\n",
    "    # Save the modified notebook\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        nbformat.write(notebook, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def process_notebooks_in_folder(folder_path, operation=split_import_and_code_cells):\n",
    "    \"\"\"\n",
    "    Traverse all .ipynb files in a folder and apply the cell-splitting logic.\n",
    "    \"\"\"\n",
    "    if isinstance(folder_path, Path):\n",
    "        folder_path = folder_path.as_posix()\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.ipynb'):\n",
    "                notebook_path = os.path.join(root, file)\n",
    "                print(f\"Processing {notebook_path}\")\n",
    "                operate_on_notebook_in(notebook_path, operation=operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "def nbscholar_separate(path:str=\".\"):\n",
    "    if os.path.isfile(path):\n",
    "        return operate_on_notebook_in(path, split_import_and_code_cells)\n",
    "    \n",
    "    notebook_path = guess_notebooks_path(path)\n",
    "    if notebook_path is None:\n",
    "        notebook_path = path\n",
    "    process_notebooks_in_folder(notebook_path)\n",
    "functions.append(nbscholar_separate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "functions_dict = {\n",
    "    v.__name__.replace(\"nbscholar_\", \"\"):v for v in functions\n",
    "}\n",
    "\n",
    "# 整体路由\n",
    "@call_parse\n",
    "def nbscholar(mode:str=\"export\", *args, **kwargs):\n",
    "    function = functions_dict.get(mode, None)\n",
    "    if function is None:\n",
    "        raise ValueError(f\"Invalid mode: {mode}\")\n",
    "    function(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "fileId": "31f2d027-914b-4fc6-ab85-8acdb1e874ce",
  "filePath": "/root/repos/peft/BoGuan_YueQu/third_party/infras/ScholarlyInfrastructure/src/notebooks/03_nbscholar (nbdev extensions).ipynb",
  "kernelspec": {
   "display_name": "yuequ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
