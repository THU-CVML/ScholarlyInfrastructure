{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2450dce",
   "metadata": {},
   "source": [
    "# OpenAI API Related\n",
    "\n",
    "> å¸®åŠ©OPENAI API æ¨ç†æœ‰å…³çš„å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b01f45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp llm_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b097b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920b9361",
   "metadata": {},
   "source": [
    "pandasæ ¼å¼æ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8453dc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "\n",
    "def make_info_df(df, n_samples=2):\n",
    "    \"\"\"\n",
    "    æ„é€ åŒ…å« column_name, dtype å’Œå‰ n_samples è¡Œæ ·æœ¬å€¼çš„è¡¨æ ¼\n",
    "    \"\"\"\n",
    "    info_df = pd.DataFrame({\n",
    "        'column_name': df.columns,\n",
    "        'dtype': df.dtypes.values\n",
    "    })\n",
    "    # æ·»åŠ å‰ n_samples è¡Œæ ·æœ¬å€¼\n",
    "    for i in range(n_samples):\n",
    "        col = f'sample{i+1}'\n",
    "        info_df[col] = df.iloc[i].values\n",
    "    return info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0db17173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pydantic\n",
    "\n",
    "def get_pydantic_version():\n",
    "    \"\"\"\n",
    "    åˆ¤æ–­å½“å‰ä½¿ç”¨çš„æ˜¯ Pydantic 1 è¿˜æ˜¯ Pydantic 2\n",
    "    :return: ç‰ˆæœ¬å· 1 æˆ– 2\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if pydantic.VERSION.startswith('1'):\n",
    "            return 1\n",
    "        elif pydantic.VERSION.startswith('2'):\n",
    "            return 2\n",
    "        else:\n",
    "            raise ValueError(f\"ä¸æ”¯æŒçš„ Pydantic ç‰ˆæœ¬: {pydantic.VERSION}\")\n",
    "    except AttributeError:\n",
    "        # Pydantic 1 å¯èƒ½æ²¡æœ‰ VERSION å±æ€§ï¼Œé€šè¿‡å…¶ä»–æ–¹å¼åˆ¤æ–­\n",
    "        try:\n",
    "            from pydantic.main import ModelMetaclass\n",
    "            return 1\n",
    "        except ImportError:\n",
    "            return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebcd1793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pydantic_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21924c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "\n",
    "def is_url(s: str) -> bool:\n",
    "    \"\"\"åˆ¤æ–­æ˜¯å¦ä¸ºURLï¼ˆåŒ…å«http/https/ftp/fileç­‰åè®®ï¼‰\"\"\"\n",
    "    # 1. è¯­æ³•æ ¡éªŒï¼šåè®®å‰ç¼€ + ://ï¼ˆfile:// ä¹Ÿç¬¦åˆï¼‰\n",
    "    url_pattern = r'^[a-zA-Z][a-zA-Z0-9+.-]*://[^\\s]*$'\n",
    "    if not re.match(url_pattern, s.strip()):\n",
    "        return False\n",
    "    # 2. è§£æåè®®ï¼Œç¡®è®¤æ˜¯åˆæ³•URLåè®®\n",
    "    parsed = urlparse(s)\n",
    "    valid_schemes = {'http', 'https', 'ftp', 'ftps', 'sftp', 'ssh', 'telnet', 'file'}\n",
    "    return parsed.scheme.lower() in valid_schemes\n",
    "\n",
    "def is_local_file_path(s: str) -> bool:\n",
    "    \"\"\"åˆ¤æ–­æ˜¯å¦ä¸ºæœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼ˆéURLæ ¼å¼ï¼‰\"\"\"\n",
    "    # æ’é™¤URLï¼ˆé¿å…ä¸file://æ··æ·†ï¼‰\n",
    "    if is_url(s):\n",
    "        return False\n",
    "    # æ£€æŸ¥æ˜¯å¦ç¬¦åˆæ“ä½œç³»ç»Ÿçš„æ–‡ä»¶è·¯å¾„æ ¼å¼\n",
    "    # ç®€åŒ–åˆ¤æ–­ï¼šåŒ…å«è·¯å¾„åˆ†éš”ç¬¦ï¼Œæˆ–ç¬¦åˆç›˜ç¬¦ï¼ˆWindowsï¼‰/æ ¹ç›®å½•ï¼ˆLinux/macOSï¼‰ç‰¹å¾\n",
    "    s_stripped = s.strip()\n",
    "    if not s_stripped:\n",
    "        return False\n",
    "    # Windowsè·¯å¾„ç‰¹å¾ï¼šç›˜ç¬¦ï¼ˆå¦‚C:ï¼‰+ åæ–œæ æˆ–æ–œæ \n",
    "    windows_pattern = r'^[a-zA-Z]:[\\\\/].*'\n",
    "    # Linux/macOSè·¯å¾„ç‰¹å¾ï¼šæ ¹ç›®å½•/æˆ–ç›¸å¯¹è·¯å¾„./../\n",
    "    unix_pattern = r'^(/|\\./|\\.\\./).*'\n",
    "    # è¿˜å¯ä»¥é€šè¿‡å°è¯•è§£æè·¯å¾„æ˜¯å¦åˆæ³•è¿›ä¸€æ­¥éªŒè¯ï¼ˆå¯é€‰ï¼‰\n",
    "    try:\n",
    "        # å°è¯•è§„èŒƒåŒ–è·¯å¾„ï¼ˆè‹¥æŠ¥é”™åˆ™ä¸æ˜¯æœ‰æ•ˆè·¯å¾„ï¼‰\n",
    "        os.path.normpath(s_stripped)\n",
    "        return re.match(windows_pattern, s_stripped) is not None or \\\n",
    "               re.match(unix_pattern, s_stripped) is not None\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cd15d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.baidu.com:\n",
      "  æ˜¯URL: True\n",
      "  æ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„: False\n",
      "\n",
      "ftp://ftp.example.com/file.zip:\n",
      "  æ˜¯URL: True\n",
      "  æ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„: False\n",
      "\n",
      "file:///C:/Users/test.txt:\n",
      "  æ˜¯URL: True\n",
      "  æ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„: False\n",
      "\n",
      "C:\\Users\\test.txt:\n",
      "  æ˜¯URL: False\n",
      "  æ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„: True\n",
      "\n",
      "/home/user/docs.pdf:\n",
      "  æ˜¯URL: False\n",
      "  æ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„: True\n",
      "\n",
      "./data/report.csv:\n",
      "  æ˜¯URL: False\n",
      "  æ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„: True\n",
      "\n",
      "www.baidu.com:\n",
      "  æ˜¯URL: False\n",
      "  æ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„: False\n",
      "\n",
      "tel:123456:\n",
      "  æ˜¯URL: False\n",
      "  æ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•ç”¨ä¾‹\n",
    "test_cases = [\n",
    "    # URL\n",
    "    \"https://www.baidu.com\",    # URL â†’ True\n",
    "    \"ftp://ftp.example.com/file.zip\",  # URL â†’ True\n",
    "    \"file:///C:/Users/test.txt\",  # æœ¬åœ°æ–‡ä»¶URL â†’ Trueï¼ˆis_urlè¿”å›Trueï¼‰\n",
    "    # æœ¬åœ°æ–‡ä»¶è·¯å¾„\n",
    "    \"C:\\\\Users\\\\test.txt\",     # Windowsæœ¬åœ°è·¯å¾„ â†’ True\n",
    "    \"/home/user/docs.pdf\",     # Linuxæœ¬åœ°è·¯å¾„ â†’ True\n",
    "    \"./data/report.csv\",       # ç›¸å¯¹è·¯å¾„ â†’ True\n",
    "    # å…¶ä»–\n",
    "    \"www.baidu.com\",           # æ—¢éURLä¹Ÿéè·¯å¾„ â†’ ä¸¤è€…éƒ½False\n",
    "    \"tel:123456\",              # URIä½†éURL/è·¯å¾„ â†’ ä¸¤è€…éƒ½False\n",
    "]\n",
    "\n",
    "for case in test_cases:\n",
    "    url_flag = is_url(case)\n",
    "    path_flag = is_local_file_path(case)\n",
    "    print(f\"{case}:\")\n",
    "    print(f\"  æ˜¯URL: {url_flag}\")\n",
    "    print(f\"  æ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„: {path_flag}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e05894c",
   "metadata": {},
   "source": [
    "### è¾…åŠ©å‡½æ•°ï¼šåŸºäºæ–‡ä»¶å†…å®¹æ£€æµ‹æ‰©å±•å\n",
    "éœ€è¦å…ˆå®‰è£…: pip install filetype\n",
    "å¦‚æœæ²¡æœ‰ filetypeï¼Œè¿™ä¸ªå‡½æ•°å¯ä»¥å›é€€åˆ°é»˜è®¤è¡Œä¸ºæˆ–è€…æŠ¥é”™ï¼Œè¿™é‡Œæ¼”ç¤ºæœ€ç¨³å¥çš„ filetype æ–¹å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f1df9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import struct\n",
    "import aiofiles\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "# Try importing filetype, treat as optional dependency\n",
    "try:\n",
    "    import filetype\n",
    "except ImportError:\n",
    "    filetype = None\n",
    "\n",
    "async def detect_and_rename(\n",
    "    fpath: Path, # The current file path\n",
    "    verbose: bool = False # Whether to print log messages\n",
    ") -> Path:\n",
    "    \"Async reads file magic bytes (using filetype or fallback) and renames if needed.\"\n",
    "    \n",
    "    final_path = fpath\n",
    "    if not fpath.exists(): return fpath\n",
    "\n",
    "    # Common magic numbers mapping (Fallback if filetype is missing/fails)\n",
    "    signatures = {\n",
    "        b'\\xFF\\xD8\\xFF': '.jpg',\n",
    "        b'\\x89PNG\\r\\n\\x1a\\n': '.png',\n",
    "        b'GIF87a': '.gif',\n",
    "        b'GIF89a': '.gif',\n",
    "        b'%PDF': '.pdf',\n",
    "        b'\\x1aE\\xdf\\xa3': '.webm', \n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Async read the first 2KB (enough for filetype and most headers)\n",
    "        head = b\"\"\n",
    "        async with aiofiles.open(fpath, 'rb') as f:\n",
    "            head = await f.read(2048)\n",
    "            \n",
    "        ext = None\n",
    "        \n",
    "        # --- Strategy 1: Use 'filetype' library if available ---\n",
    "        if filetype:\n",
    "            kind = filetype.guess(head)\n",
    "            if kind:\n",
    "                ext = '.' + kind.extension\n",
    "        \n",
    "        # --- Strategy 2: Fallback manual detection ---\n",
    "        if ext is None:\n",
    "            # Check dictionary signatures\n",
    "            for sig, likely_ext in signatures.items():\n",
    "                if head.startswith(sig):\n",
    "                    ext = likely_ext\n",
    "                    break\n",
    "            \n",
    "            # Check MP4/MOV (ftyp at index 4)\n",
    "            if ext is None and len(head) > 12:\n",
    "                if head[4:8] == b'ftyp':\n",
    "                    ext = '.mp4'\n",
    "\n",
    "        # --- Rename Logic ---\n",
    "        if ext:\n",
    "            if fpath.suffix.lower() != ext:\n",
    "                new_path = fpath.with_suffix(ext)\n",
    "                # Rename is an OS metadata op, typically fast enough to be sync\n",
    "                fpath.rename(new_path)\n",
    "                final_path = new_path\n",
    "                if verbose: print(f\"ğŸ”„ Renamed: {fpath.name} -> {final_path.name}\")\n",
    "            elif verbose:\n",
    "                print(f\"âœ… Extension verified: {ext}\")\n",
    "        else:\n",
    "            if verbose: print(\"âš ï¸ Could not detect file type, keeping original name.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        if verbose: print(f\"âš ï¸ Extension detection failed: {e}\")\n",
    "        \n",
    "    return final_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32a20934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Created dummy file: test_image_no_ext\n",
      "ğŸ”„ Renamed: test_image_no_ext -> test_image_no_ext.png\n",
      "âœ… Async type detection passed\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def test_detection():\n",
    "    # 1. Create a dummy file without extension (Mocking a PNG)\n",
    "    # PNG Signature: 89 50 4E 47 0D 0A 1A 0A\n",
    "    png_header = b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR' \n",
    "    dummy_path = Path(\"test_image_no_ext\")\n",
    "    \n",
    "    async with aiofiles.open(dummy_path, 'wb') as f:\n",
    "        await f.write(png_header)\n",
    "        \n",
    "    print(f\"ğŸ§ª Created dummy file: {dummy_path}\")\n",
    "\n",
    "    try:\n",
    "        # 2. Run async detection\n",
    "        # Note: If you don't have filetype installed, this tests the fallback logic.\n",
    "        # If you do, it tests the library logic. Both should result in .png\n",
    "        fixed_path = await detect_and_rename(dummy_path, verbose=True)\n",
    "        \n",
    "        # 3. Assertions\n",
    "        assert fixed_path.suffix == '.png', f\"Expected .png, got {fixed_path.suffix}\"\n",
    "        assert fixed_path.exists()\n",
    "        assert not dummy_path.exists()\n",
    "        print(\"âœ… Async type detection passed\")\n",
    "        \n",
    "    finally:\n",
    "        # Cleanup\n",
    "        if fixed_path.exists(): fixed_path.unlink()\n",
    "        if dummy_path.exists(): dummy_path.unlink()\n",
    "\n",
    "await test_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47960e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install aiofiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c607b341",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import aiohttp\n",
    "import aiofiles\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from typing import Optional, Union\n",
    "from urllib.parse import urlparse, unquote\n",
    "\n",
    "async def download_file(\n",
    "    video_url: str, # The URL to download\n",
    "    verbose: bool = False, # Toggle verbose logging\n",
    "    target: Optional[Union[str, Path]] = None # Target directory or full filepath\n",
    ") -> Optional[str]:\n",
    "    \"Async downloads a file, then auto-detects and corrects the file extension.\"\n",
    "    \n",
    "    save_path: Path = Path()\n",
    "    \n",
    "    try:\n",
    "        # --- 1. Setup Path ---\n",
    "        parsed_url = urlparse(video_url)\n",
    "        url_filename = Path(unquote(parsed_url.path)).name\n",
    "        if not url_filename: url_filename = \"downloaded_file.tmp\"\n",
    "\n",
    "        if target:\n",
    "            target_path = Path(target)\n",
    "            if target_path.is_dir():\n",
    "                save_path = target_path / url_filename\n",
    "            else:\n",
    "                save_path = target_path\n",
    "                save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        else:\n",
    "            suffix = Path(url_filename).suffix\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:\n",
    "                save_path = Path(tmp.name)\n",
    "\n",
    "        if verbose: print(f\"â¬‡ï¸ Start Download: {video_url} -> {save_path}\")\n",
    "\n",
    "        # --- 2. Async Download ---\n",
    "        timeout = aiohttp.ClientTimeout(total=600)\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(video_url, timeout=timeout) as response:\n",
    "                if response.status != 200:\n",
    "                    if verbose: print(f\"âŒ Status {response.status}\")\n",
    "                    if save_path.exists(): save_path.unlink()\n",
    "                    return None\n",
    "\n",
    "                async with aiofiles.open(save_path, \"wb\") as f:\n",
    "                    async for chunk in response.content.iter_chunked(1024 * 1024):\n",
    "                        await f.write(chunk)\n",
    "\n",
    "        # --- 3. Async Type Detection & Rename ---\n",
    "        # Await the new async helper function\n",
    "        final_path = await detect_and_rename(save_path, verbose=verbose)\n",
    "        \n",
    "        return str(final_path.absolute())\n",
    "\n",
    "    except Exception as e:\n",
    "        if verbose: print(f\"âŒ Error: {e}\")\n",
    "        if save_path and save_path.exists():\n",
    "            try: save_path.unlink()\n",
    "            except OSError: pass\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "768e380f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸‹è½½å®Œæˆï¼Œæœ¬åœ°è·¯å¾„ï¼š/tmp/tmpbusenzhs.mp4\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "video_url = \"http://www.w3school.com.cn/example/html5/mov_bbb.mp4\"  # æ›¿æ¢ä¸ºå®é™…URL\n",
    "input_video = await download_file(video_url)\n",
    "if input_video:\n",
    "    print(f\"ä¸‹è½½å®Œæˆï¼Œæœ¬åœ°è·¯å¾„ï¼š{input_video}\")\n",
    "        # ä½¿ç”¨å®Œæˆåæ‰‹åŠ¨åˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰\n",
    "        # os.unlink(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd42159d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Start Download: http://www.w3school.com.cn/example/html5/mov_bbb.mp4 -> test/vie.any.suffix\n",
      "ğŸ”„ Renamed: vie.any.suffix -> vie.any.mp4\n",
      "ä¸‹è½½å®Œæˆï¼Œæœ¬åœ°è·¯å¾„ï¼š/mnt/bn/pippit-omni-eval/mlx/users/yecanming/repos/BoGuan_YueQu/third_party/infras/ScholarlyInfrastructure/src/notebooks/test/vie.any.mp4\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "video_url = \"http://www.w3school.com.cn/example/html5/mov_bbb.mp4\"  # æ›¿æ¢ä¸ºå®é™…URL\n",
    "input_video = await download_file(video_url, True, target=\"./test/vie.any.suffix\")\n",
    "if input_video:\n",
    "    print(f\"ä¸‹è½½å®Œæˆï¼Œæœ¬åœ°è·¯å¾„ï¼š{input_video}\")\n",
    "        # ä½¿ç”¨å®Œæˆåæ‰‹åŠ¨åˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰\n",
    "        # os.unlink(video_path)\n",
    "    os.remove(input_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39c6ab79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Downloading to: /tmp/tmpv4kgrn36/mystery_file\n",
      "â¬‡ï¸ Start Download: https://www.w3schools.com/w3css/img_lights.jpg -> /tmp/tmpv4kgrn36/mystery_file\n",
      "ğŸ”„ Renamed: mystery_file -> mystery_file.jpg\n",
      "ğŸ“‚ Final Path: /tmp/tmpv4kgrn36/mystery_file.jpg\n",
      "âœ… Download and Rename Integration Test Passed\n"
     ]
    }
   ],
   "source": [
    "async def test_download_integration():\n",
    "    # Test with a known image URL that has an extension, \n",
    "    # but we will force the target to NOT have one to trigger the rename logic.\n",
    "    url = \"https://www.w3schools.com/w3css/img_lights.jpg\"\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        # Force a target path without extension\n",
    "        target_path = Path(td) / \"mystery_file\"\n",
    "        \n",
    "        print(f\"ğŸš€ Downloading to: {target_path}\")\n",
    "        result = await download_file(url, verbose=True, target=target_path)\n",
    "        \n",
    "        if result:\n",
    "            res_path = Path(result)\n",
    "            print(f\"ğŸ“‚ Final Path: {res_path}\")\n",
    "            \n",
    "            # Check if it recognized it as a jpg and renamed it\n",
    "            assert res_path.suffix == '.jpg', \"Should detect .jpg extension\"\n",
    "            assert res_path.name != \"mystery_file\", \"Filename should have changed\"\n",
    "            assert res_path.exists()\n",
    "            print(\"âœ… Download and Rename Integration Test Passed\")\n",
    "        else:\n",
    "            print(\"âŒ Download failed (check network)\")\n",
    "\n",
    "await test_download_integration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02d11b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import base64\n",
    "import os\n",
    "import asyncio\n",
    "\n",
    "try:\n",
    "    import aiofiles\n",
    "except ImportError:\n",
    "    print(\"è¯·å…ˆå®‰è£… 'aiofiles' åº“: !pip install aiofiles\")\n",
    "\n",
    "async def local_video_to_base64_uri(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    å¼‚æ­¥åœ°å°†æœ¬åœ°è§†é¢‘æ–‡ä»¶è½¬æ¢ä¸º Base64 ç¼–ç çš„æ•°æ® URIã€‚\n",
    "    \n",
    "    æ ¼å¼éµå¾ª: data:video/<è§†é¢‘æ ¼å¼>;base64,<Base64ç¼–ç >ï¼Œå…¶ä¸­ï¼Œ\n",
    "    è§†é¢‘æ ¼å¼: æ”¯æŒ mp4, avi, movã€‚\n",
    "    Base64ç¼–ç : è§†é¢‘æ–‡ä»¶çš„ Base64 ç¼–ç ã€‚\n",
    "\n",
    "    Args:\n",
    "        file_path: æœ¬åœ°è§†é¢‘æ–‡ä»¶çš„è·¯å¾„ã€‚\n",
    "\n",
    "    Returns:\n",
    "        ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ŒåŒ…å«äº†è§†é¢‘çš„ Base64 ç¼–ç æ•°æ® URIã€‚\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: å¦‚æœè§†é¢‘æ ¼å¼ä¸æ˜¯ 'mp4', 'avi', æˆ– 'mov' ä¹‹ä¸€ã€‚\n",
    "        FileNotFoundError: å¦‚æœåœ¨ file_path æŒ‡å®šçš„è·¯å¾„ä¸‹æ‰¾ä¸åˆ°æ–‡ä»¶ã€‚\n",
    "    \"\"\"\n",
    "    supported_formats = {'mp4', 'avi', 'mov'}\n",
    "    \n",
    "    # ä»è·¯å¾„ä¸­è·å–æ–‡ä»¶æ‰©å±•åä½œä¸ºè§†é¢‘æ ¼å¼\n",
    "    file_extension = file_path.split('.')[-1].lower()\n",
    "\n",
    "    if file_extension not in supported_formats:\n",
    "        raise ValueError(f\"ä¸æ”¯æŒçš„è§†é¢‘æ ¼å¼: '{file_extension}'ã€‚æ”¯æŒçš„æ ¼å¼ä¸º: {', '.join(supported_formats)}\")\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}\")\n",
    "\n",
    "    # å¼‚æ­¥è¯»å–æ–‡ä»¶\n",
    "    async with aiofiles.open(file_path, 'rb') as video_file:\n",
    "        video_bytes = await video_file.read()\n",
    "    \n",
    "    # è¿›è¡Œ Base64 ç¼–ç \n",
    "    base64_encoded_video = base64.b64encode(video_bytes).decode('utf-8')\n",
    "    \n",
    "    # æ‹¼æ¥æˆæœ€ç»ˆçš„ Data URI å­—ç¬¦ä¸²\n",
    "    return f\"data:video/{file_extension};base64,{base64_encoded_video}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5cbdb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨è½¬æ¢æ–‡ä»¶: /tmp/tmp8gzgpnrt.mp4\n",
      "è½¬æ¢æˆåŠŸï¼\n",
      "ç”Ÿæˆçš„æ•°æ® URI (å‰100ä¸ªå­—ç¬¦): data:video/mp4;base64,AAAAHGZ0eXBtcDQyAAAAAG1wNDJpc29tYXZjMQAAAIRmcmVlAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA...\n",
      "ç¤ºä¾‹æ–‡ä»¶ '/tmp/tmp8gzgpnrt.mp4' å·²ä¿ç•™ï¼Œæ‚¨å¯ä»¥æ£€æŸ¥æˆ–æ‰‹åŠ¨åˆ é™¤ã€‚\n"
     ]
    }
   ],
   "source": [
    "\"\"\"ä¸€ä¸ªè¿è¡Œç¤ºä¾‹çš„å¼‚æ­¥å‡½æ•°\"\"\"\n",
    "# åˆ›å»ºä¸€ä¸ªç”¨äºæ¼”ç¤ºçš„è™šæ‹Ÿè§†é¢‘æ–‡ä»¶\n",
    "# åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œè¯·å°†æ­¤è·¯å¾„æ›¿æ¢ä¸ºæ‚¨çš„è§†é¢‘æ–‡ä»¶è·¯å¾„\n",
    "dummy_video_path = input_video or \"/tmp/test.mp4\"\n",
    "if not os.path.exists(dummy_video_path):\n",
    "    print(f\"æ­£åœ¨åˆ›å»ºè™šæ‹Ÿæ–‡ä»¶ç”¨äºæ¼”ç¤º: {dummy_video_path}\")\n",
    "    with open(dummy_video_path, \"wb\") as f:\n",
    "        # è¿™æ˜¯ä¸€ä¸ªåˆæ³•çš„ã€ä½†éå¸¸å°çš„ MP4 æ–‡ä»¶å†…å®¹\n",
    "        f.write(b'\\x00\\x00\\x00\\x18ftypmp42\\x00\\x00\\x00\\x00isommp42')\n",
    "\n",
    "try:\n",
    "    print(f\"æ­£åœ¨è½¬æ¢æ–‡ä»¶: {dummy_video_path}\")\n",
    "    data_uri = await local_video_to_base64_uri(dummy_video_path)\n",
    "    print(\"è½¬æ¢æˆåŠŸï¼\")\n",
    "    # é€šå¸¸ Data URI ä¼šéå¸¸é•¿ï¼Œè¿™é‡Œåªæ‰“å°å‰100ä¸ªå­—ç¬¦\n",
    "    print(f\"ç”Ÿæˆçš„æ•°æ® URI (å‰100ä¸ªå­—ç¬¦): {data_uri[:100]}...\")\n",
    "except (ValueError, FileNotFoundError, NameError) as e:\n",
    "    print(f\"å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "finally:\n",
    "    # ç¤ºä¾‹è¿è¡Œåï¼Œæ‚¨å¯ä»¥é€‰æ‹©ä¿ç•™æˆ–åˆ é™¤è¿™ä¸ªè™šæ‹Ÿæ–‡ä»¶\n",
    "    if os.path.exists(dummy_video_path):\n",
    "        print(f\"ç¤ºä¾‹æ–‡ä»¶ '{dummy_video_path}' å·²ä¿ç•™ï¼Œæ‚¨å¯ä»¥æ£€æŸ¥æˆ–æ‰‹åŠ¨åˆ é™¤ã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35318516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import re\n",
    "from typing import Optional, Tuple\n",
    "def separate_think_and_other(text: str) -> Tuple[Optional[str], str]:\n",
    "    \"\"\"\n",
    "    ä»æ–‡æœ¬ä¸­åˆ†ç¦» <think> æ ‡ç­¾å†…å®¹å’Œå…¶ä½™å†…å®¹ã€‚\n",
    "\n",
    "    Args:\n",
    "        text: åŒ…å«æˆ–ä¸åŒ…å« <think> æ ‡ç­¾çš„åŸå§‹å­—ç¬¦ä¸²ã€‚\n",
    "\n",
    "    Returns:\n",
    "        ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«ä¸¤éƒ¨åˆ†ï¼š\n",
    "        - ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯æ‰€æœ‰ <think> æ ‡ç­¾å†…å†…å®¹çš„åˆå¹¶å­—ç¬¦ä¸²ï¼ˆä»¥æ¢è¡Œç¬¦åˆ†éš”ï¼‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä¸º Noneã€‚\n",
    "        - ç¬¬äºŒä¸ªå…ƒç´ æ˜¯å»é™¤ <think> æ ‡ç­¾åå‰©ä½™å†…å®¹çš„åˆå¹¶å­—ç¬¦ä¸²ã€‚\n",
    "    \"\"\"\n",
    "    # ä½¿ç”¨ re.findall æ‰¾åˆ°æ‰€æœ‰ <think> æ ‡ç­¾çš„å†…å®¹\n",
    "    # re.DOTALL æ ‡å¿—è®© '.' å¯ä»¥åŒ¹é…åŒ…æ‹¬æ¢è¡Œç¬¦åœ¨å†…çš„ä»»ä½•å­—ç¬¦\n",
    "    think_parts = re.findall(r'<think>(.*?)</think>', text, re.DOTALL)\n",
    "    \n",
    "    if think_parts:\n",
    "        # åˆå¹¶æ‰€æœ‰ <think> æ ‡ç­¾å†…çš„å†…å®¹ï¼Œä½¿ç”¨æ¢è¡Œç¬¦åˆ†éš”\n",
    "        think_content = \"\\n\".join(part.strip() for part in think_parts)\n",
    "    else:\n",
    "        think_content = None\n",
    "\n",
    "    # ä½¿ç”¨ re.split æ¥è·å– <think> æ ‡ç­¾å¤–çš„å†…å®¹\n",
    "    other_parts = re.split(r'<think>.*?</think>', text, flags=re.DOTALL)\n",
    "    # åˆå¹¶æ‰€æœ‰æ ‡ç­¾å¤–çš„å†…å®¹ï¼Œå¹¶æ¸…ç†é¦–å°¾åŠä¸­é—´å¤šä½™çš„ç©ºç™½\n",
    "    other_content = \"\\n\".join(part.strip() for part in other_parts if part.strip())\n",
    "\n",
    "    return think_content, other_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6fdb669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æµ‹è¯•ç”¨ä¾‹ 1:\n",
      "åŸå§‹å­—ç¬¦ä¸²: 'è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å­—ç¬¦ä¸²'\n",
      "åŒ…è£¹å†…å®¹åˆå¹¶: None\n",
      "å‰©ä½™éƒ¨åˆ†åˆå¹¶: 'è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å­—ç¬¦ä¸²'\n",
      "--------------------------------------------------\n",
      "æµ‹è¯•ç”¨ä¾‹ 2:\n",
      "åŸå§‹å­—ç¬¦ä¸²: 'æ™®é€šæ–‡æœ¬<think>è¿™æ˜¯æ€è€ƒå†…å®¹</think>å…¶ä»–éƒ¨åˆ†'\n",
      "åŒ…è£¹å†…å®¹åˆå¹¶: 'è¿™æ˜¯æ€è€ƒå†…å®¹'\n",
      "å‰©ä½™éƒ¨åˆ†åˆå¹¶: 'æ™®é€šæ–‡æœ¬\\nå…¶ä»–éƒ¨åˆ†'\n",
      "--------------------------------------------------\n",
      "æµ‹è¯•ç”¨ä¾‹ 3:\n",
      "åŸå§‹å­—ç¬¦ä¸²: '<think>åªæœ‰æ€è€ƒå†…å®¹</think>'\n",
      "åŒ…è£¹å†…å®¹åˆå¹¶: 'åªæœ‰æ€è€ƒå†…å®¹'\n",
      "å‰©ä½™éƒ¨åˆ†åˆå¹¶: ''\n",
      "--------------------------------------------------\n",
      "æµ‹è¯•ç”¨ä¾‹ 4:\n",
      "åŸå§‹å­—ç¬¦ä¸²: 'æ— æ€è€ƒå†…å®¹çš„æ™®é€šæ–‡æœ¬'\n",
      "åŒ…è£¹å†…å®¹åˆå¹¶: None\n",
      "å‰©ä½™éƒ¨åˆ†åˆå¹¶: 'æ— æ€è€ƒå†…å®¹çš„æ™®é€šæ–‡æœ¬'\n",
      "--------------------------------------------------\n",
      "æµ‹è¯•ç”¨ä¾‹ 5:\n",
      "åŸå§‹å­—ç¬¦ä¸²: 'å¤šæ€è€ƒéƒ¨åˆ†<think>æ€è€ƒ1</think>ä¸­é—´æ–‡æœ¬<think>æ€è€ƒ2</think>ç»“å°¾æ–‡æœ¬'\n",
      "åŒ…è£¹å†…å®¹åˆå¹¶: 'æ€è€ƒ1\\næ€è€ƒ2'\n",
      "å‰©ä½™éƒ¨åˆ†åˆå¹¶: 'å¤šæ€è€ƒéƒ¨åˆ†\\nä¸­é—´æ–‡æœ¬\\nç»“å°¾æ–‡æœ¬'\n",
      "--------------------------------------------------\n",
      "æµ‹è¯•ç”¨ä¾‹ 6:\n",
      "åŸå§‹å­—ç¬¦ä¸²: '\\n    <think>\\nGot it, let\\'s tackle this problem. First, the user is asking about what the person is doing, whether the sound is pleasant, and if the drawing looks good. They want the output in a specific JSON format called RaterResult with description, speech_to_text, draw_quality, and sound_quality.\\n\\nFirst, analyze the video: The video shows someone using a stylus on a tablet to draw a guitar. So the description should capture that. Then, the speech: the person says \"Hello, take a look at what I\\'m drawing.\" So speech_to_text is that sentence. Then for draw_quality: the drawing is a simple, clean guitar illustration, which is decent but not overly complex, so maybe 4 stars. Sound quality: the voice is clear, no background noise, so 5 stars.\\n\\nLet\\'s check each part:\\n\\nDescription: \"A person is using a stylus to draw a guitar illustration on a tablet.\"\\n\\nSpeech to text: \"Hello, take a look at what I\\'m drawing.\"\\n\\nDraw quality: The drawing is clear, well-defined lines, simple but neat. So 4 stars (since it\\'s good but maybe not perfect for a highly detailed work, but the question is \"ç”»å¾—å¥½çœ‹ä¸?\" so 4 is reasonable).\\n\\nSound quality: The voice is clear, no distortion, so 5 stars.\\n\\nNow structure into JSON as per schema.\\n</think>\\n\\n{\\n    \"description\": \"A person is using a stylus to draw a guitar illustration on a tablet.\",\\n    \"speech_to_text\": \"Hello, take a look at what I\\'m drawing.\",\\n    \"draw_quality\": 4,\\n    \"sound_quality\": 5\\n}\\n    '\n",
      "åŒ…è£¹å†…å®¹åˆå¹¶: 'Got it, let\\'s tackle this problem. First, the user is asking about what the person is doing, whether the sound is pleasant, and if the drawing looks good. They want the output in a specific JSON format called RaterResult with description, speech_to_text, draw_quality, and sound_quality.\\n\\nFirst, analyze the video: The video shows someone using a stylus on a tablet to draw a guitar. So the description should capture that. Then, the speech: the person says \"Hello, take a look at what I\\'m drawing.\" So speech_to_text is that sentence. Then for draw_quality: the drawing is a simple, clean guitar illustration, which is decent but not overly complex, so maybe 4 stars. Sound quality: the voice is clear, no background noise, so 5 stars.\\n\\nLet\\'s check each part:\\n\\nDescription: \"A person is using a stylus to draw a guitar illustration on a tablet.\"\\n\\nSpeech to text: \"Hello, take a look at what I\\'m drawing.\"\\n\\nDraw quality: The drawing is clear, well-defined lines, simple but neat. So 4 stars (since it\\'s good but maybe not perfect for a highly detailed work, but the question is \"ç”»å¾—å¥½çœ‹ä¸?\" so 4 is reasonable).\\n\\nSound quality: The voice is clear, no distortion, so 5 stars.\\n\\nNow structure into JSON as per schema.'\n",
      "å‰©ä½™éƒ¨åˆ†åˆå¹¶: '{\\n    \"description\": \"A person is using a stylus to draw a guitar illustration on a tablet.\",\\n    \"speech_to_text\": \"Hello, take a look at what I\\'m drawing.\",\\n    \"draw_quality\": 4,\\n    \"sound_quality\": 5\\n}'\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•ç”¨ä¾‹\n",
    "test_cases = [\n",
    "    \"è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å­—ç¬¦ä¸²\",\n",
    "    \"æ™®é€šæ–‡æœ¬<think>è¿™æ˜¯æ€è€ƒå†…å®¹</think>å…¶ä»–éƒ¨åˆ†\",\n",
    "    \"<think>åªæœ‰æ€è€ƒå†…å®¹</think>\",\n",
    "    \"æ— æ€è€ƒå†…å®¹çš„æ™®é€šæ–‡æœ¬\",\n",
    "    \"å¤šæ€è€ƒéƒ¨åˆ†<think>æ€è€ƒ1</think>ä¸­é—´æ–‡æœ¬<think>æ€è€ƒ2</think>ç»“å°¾æ–‡æœ¬\",\n",
    "    \"\"\"\n",
    "    <think>\n",
    "Got it, let's tackle this problem. First, the user is asking about what the person is doing, whether the sound is pleasant, and if the drawing looks good. They want the output in a specific JSON format called RaterResult with description, speech_to_text, draw_quality, and sound_quality.\n",
    "\n",
    "First, analyze the video: The video shows someone using a stylus on a tablet to draw a guitar. So the description should capture that. Then, the speech: the person says \"Hello, take a look at what I'm drawing.\" So speech_to_text is that sentence. Then for draw_quality: the drawing is a simple, clean guitar illustration, which is decent but not overly complex, so maybe 4 stars. Sound quality: the voice is clear, no background noise, so 5 stars.\n",
    "\n",
    "Let's check each part:\n",
    "\n",
    "Description: \"A person is using a stylus to draw a guitar illustration on a tablet.\"\n",
    "\n",
    "Speech to text: \"Hello, take a look at what I'm drawing.\"\n",
    "\n",
    "Draw quality: The drawing is clear, well-defined lines, simple but neat. So 4 stars (since it's good but maybe not perfect for a highly detailed work, but the question is \"ç”»å¾—å¥½çœ‹ä¸?\" so 4 is reasonable).\n",
    "\n",
    "Sound quality: The voice is clear, no distortion, so 5 stars.\n",
    "\n",
    "Now structure into JSON as per schema.\n",
    "</think>\n",
    "\n",
    "{\n",
    "    \"description\": \"A person is using a stylus to draw a guitar illustration on a tablet.\",\n",
    "    \"speech_to_text\": \"Hello, take a look at what I'm drawing.\",\n",
    "    \"draw_quality\": 4,\n",
    "    \"sound_quality\": 5\n",
    "}\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "for i, case in enumerate(test_cases, 1):\n",
    "    wrapped, remaining = separate_think_and_other(case)\n",
    "    print(f\"æµ‹è¯•ç”¨ä¾‹ {i}:\")\n",
    "    print(f\"åŸå§‹å­—ç¬¦ä¸²: {case!r}\")\n",
    "    print(f\"åŒ…è£¹å†…å®¹åˆå¹¶: {wrapped!r}\")\n",
    "    print(f\"å‰©ä½™éƒ¨åˆ†åˆå¹¶: {remaining!r}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b38dd55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "def extract_code_content(text: str, target_lang: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    ä»å­—ç¬¦ä¸²ä¸­æå–ç¬¬ä¸€ä¸ª Markdown ä»£ç å—çš„å†…å®¹ã€‚\n",
    "    å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œåˆ™ç›´æ¥è¿”å›åŸæ–‡æœ¬ã€‚\n",
    "    \"\"\"\n",
    "    if target_lang is None:\n",
    "        pattern = re.compile(r\"```(?:[a-zA-Z0-9_+-]*)\\n(.*?)```\", re.DOTALL)\n",
    "    else:\n",
    "        pattern = re.compile(rf\"```{target_lang}\\n(.*?)```\", re.DOTALL)\n",
    "    match = pattern.search(text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28a68420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æµ‹è¯•ç”¨ä¾‹: 7. ä¸šåŠ¡json\n",
      "è¾“å…¥: ã€{\n",
      "    a: 1,\n",
      "    b: {\n",
      "        c: 3,\n",
      "    }\n",
      "}\n",
      "ã€‘\n",
      "è¾“å‡º: ã€{\n",
      "    a: 1,\n",
      "    b: {\n",
      "        c: 3,\n",
      "    }\n",
      "}ã€‘\n",
      "==================================================\n",
      "æµ‹è¯•ç”¨ä¾‹: 8. åŒ…è£¹çš„jsonå­—ç¬¦ä¸²\n",
      "è¾“å…¥: ã€\n",
      "```json\n",
      "{\n",
      "    a: 1,\n",
      "    b: {\n",
      "        c: 3,\n",
      "    }\n",
      "}\n",
      "```\n",
      "ã€‘\n",
      "è¾“å‡º: ã€{\n",
      "    a: 1,\n",
      "    b: {\n",
      "        c: 3,\n",
      "    }\n",
      "}ã€‘\n",
      "==================================================\n",
      "æµ‹è¯•ç”¨ä¾‹: 9. å¤šä¸ªä»£ç å—\n",
      "è¾“å…¥: ã€\n",
      "```python\n",
      "a = 3\n",
      "```\n",
      "```json\n",
      "{\n",
      "    a: 1,\n",
      "    b: {\n",
      "        c: 3,\n",
      "    }\n",
      "}\n",
      "```\n",
      "ã€‘\n",
      "è¾“å‡º: ã€{\n",
      "    a: 1,\n",
      "    b: {\n",
      "        c: 3,\n",
      "    }\n",
      "}ã€‘\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "test_cases = {\n",
    "    \"1. æœ‰è¯­è¨€æ ‡è¯†çš„ä»£ç å—\": \"\"\"è¿™é‡Œæ˜¯æè¿°\n",
    "```python\n",
    "print(\"Hello, world!\")\n",
    "x = 1 + 2\n",
    "```\n",
    "\n",
    "è¿™æ˜¯ç»“å°¾\"\"\",\n",
    "\n",
    "\"2. æ²¡æœ‰è¯­è¨€æ ‡è¯†çš„ä»£ç å—\": \"\"\"å‰é¢çš„è¯\n",
    "```\n",
    "\n",
    "```\n",
    "for i in range(3):\n",
    "    print(i)\n",
    "```\n",
    "\n",
    "åé¢çš„è¯\"\"\",\n",
    "\n",
    "\"3. åªæœ‰æ™®é€šæ–‡æœ¬ï¼Œæ²¡æœ‰ä»£ç å—\": \"\"\"print('Just plain text, no markdown code block')\"\"\",\n",
    "\n",
    "\"4. å¤šä¸ªä»£ç å—ï¼ˆåªæå–ç¬¬ä¸€ä¸ªï¼‰\": \"\"\"è¿™æ˜¯ç¬¬ä¸€ä¸ª\n",
    "\n",
    "```python\n",
    "a = 10\n",
    "```\n",
    "\n",
    "è¿™æ˜¯ç¬¬äºŒä¸ª\n",
    "\n",
    "```bash\n",
    "echo \"hi\"\n",
    "```\n",
    "\n",
    "ç»“æŸ\"\"\",\n",
    "\n",
    "\"5. ç©ºå­—ç¬¦ä¸²\": \"\",\n",
    "\n",
    "\"6. ä»£ç å—å†…å«ç©ºè¡Œ\": \"\"\"Example:\n",
    "```\n",
    "\n",
    "```python\n",
    "def foo():\n",
    "    \n",
    "    return 42\n",
    "```\n",
    "\n",
    "End\"\"\", \n",
    "\"7. ä¸šåŠ¡json\":\"\"\"{\n",
    "    a: 1,\n",
    "    b: {\n",
    "        c: 3,\n",
    "    }\n",
    "}\n",
    "\"\"\", \n",
    "\"8. åŒ…è£¹çš„jsonå­—ç¬¦ä¸²\":\"\"\"\n",
    "```json\n",
    "{\n",
    "    a: 1,\n",
    "    b: {\n",
    "        c: 3,\n",
    "    }\n",
    "}\n",
    "```\n",
    "\"\"\", \"9. å¤šä¸ªä»£ç å—\":\"\"\"\n",
    "```python\n",
    "a = 3\n",
    "```\n",
    "```json\n",
    "{\n",
    "    a: 1,\n",
    "    b: {\n",
    "        c: 3,\n",
    "    }\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "}\n",
    "\n",
    "for case_name, case_content in list(test_cases.items())[-3:]:\n",
    "    print(f\"æµ‹è¯•ç”¨ä¾‹: {case_name}\")\n",
    "    print(f\"è¾“å…¥: ã€{case_content}ã€‘\")\n",
    "    print(f\"è¾“å‡º: ã€{extract_code_content(case_content, 'json')}ã€‘\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b91932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import os\n",
    "import asyncio\n",
    "import time\n",
    "from openai import AsyncOpenAI, APIError, AsyncAzureOpenAI, OpenAI, AzureOpenAI\n",
    "from typing import Optional, Tuple\n",
    "import os\n",
    "\n",
    "\n",
    "def get_env_bool(env_var, default=False):\n",
    "    env_val = os.getenv(env_var)\n",
    "    if env_val is None:\n",
    "        return default\n",
    "    true_values = (\"true\", \"1\", \"yes\", \"on\", \"y\", \"t\")\n",
    "    return env_val.strip().lower() in true_values\n",
    "\n",
    "class Endpoint:\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_url: Optional[str] = None,\n",
    "        ip: Optional[str] = None,\n",
    "        port: Optional[int] = None,\n",
    "        api_key: Optional[str] = None,\n",
    "        model_name_or_path: Optional[str] = None,\n",
    "        use_azure: Optional[bool] = None, # https://github.com/openai/openai-python\n",
    "        api_version: Optional[str] = None,\n",
    "    ):\n",
    "        self.model_name_or_path = model_name_or_path or os.getenv(\"OPENAI_MODEL\") or \"gemini-2.5-flash\"\n",
    "\n",
    "        # Handle IPv6 addresses by wrapping them in brackets for URL compatibility\n",
    "        if ip and \":\" in ip:\n",
    "            ip = f\"[{ip}]\"\n",
    "        if ip and port:\n",
    "            self.base_url = f\"http://{ip}:{port}/v1\"\n",
    "        else:\n",
    "            self.base_url = base_url or os.getenv(\"OPENAI_BASE_URL\") or os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "        api_key = api_key or os.getenv(\"OPENAI_API_KEY\") or os.getenv(\"AZURE_OPENAI_API_KEY\") or \"not-needed\"\n",
    "        api_version = api_version or os.getenv(\"OPENAI_API_VERSION\") or os.getenv(\"AZURE_OPENAI_API_VERSION\") or \"2024-03-01-preview\"\n",
    "        use_azure = use_azure or get_env_bool(\"OPENAI_USE_AZURE\")\n",
    "        if use_azure:\n",
    "            self.async_client = AsyncAzureOpenAI(\n",
    "                azure_endpoint=self.base_url, api_key=api_key, api_version=api_version # type: ignore\n",
    "            )\n",
    "            self.client = AzureOpenAI(\n",
    "                azure_endpoint=self.base_url, api_key=api_key, api_version=api_version # type: ignore\n",
    "            )\n",
    "        else:\n",
    "            self.async_client = AsyncOpenAI(base_url=self.base_url, api_key=api_key)\n",
    "            self.client = OpenAI(base_url=self.base_url, api_key=api_key)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f\"Endpoint(base_url={self.base_url!r}, \"\n",
    "                f\"model_name_or_path={self.model_name_or_path!r}, \"\n",
    "                f\"use_azure={self.async_client.__class__.__name__.startswith('AsyncAzureOpenAI')})\")\n",
    "\n",
    "    async def chat_completions_create(self,  **kwargs):\n",
    "        return await self.async_client.chat.completions.create(\n",
    "            model=self.model_name_or_path,\n",
    "            **kwargs\n",
    "        )\n",
    "    def chat_completions_create_sync(self,  **kwargs):\n",
    "        return self.client.chat.completions.create(\n",
    "            model=self.model_name_or_path,\n",
    "            **kwargs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8a50cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"0217618192318445b3327adca1f53a304275db160b315eb146521\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"To output all files (including or excluding subdirectories) in a directory, you can use Pythonâ€™s built-in modules like `os` (traditional) or `pathlib` (modern, object-oriented). Here are several approaches:\\n\\n\\n### Method 1: List files in the **current directory (non-recursive)**  \\nUse `os.listdir()` to get all entries, then filter for files using `os.path.isfile()`.  \\n\\n\\n#### Using `os` module:  \\n```python\\nimport os\\n\\n# Target directory (e.g., current directory: \\\".\\\", or a specific path like \\\"C:/my_folder\\\")\\ndirectory = \\\".\\\"  \\n\\nfor entry in os.listdir(directory):\\n    full_path = os.path.join(directory, entry)\\n    if os.path.isfile(full_path):\\n        print(full_path)  # Print full file path\\n        # print(entry)   # Uncomment to print only the filename\\n```  \\n\\n\\n#### Using `pathlib` (Python 3.4+):  \\n`pathlib` uses object-oriented paths. `Path.iterdir()` lists all entries, and `is_file()` checks if itâ€™s a file.  \\n\\n```python\\nfrom pathlib import Path\\n\\ndirectory = Path(\\\".\\\")  # Current directory (replace with Path(\\\"your/path\\\"))\\n\\nfor item in directory.iterdir():\\n    if item.is_file():\\n        print(item)  # Print full file path (as a Path object)\\n        # print(item.name)  # Uncomment to print only the filename\\n```  \\n\\n\\n### Method 2: List files **recursively (including subdirectories)**  \\nUse `os.walk()` (recursive traversal) or `pathlib.Path.rglob()` (recursive globbing).  \\n\\n\\n#### Using `os` module (recursive):  \\n`os.walk()` traverses all subdirectories. It returns `(root, dirs, files)` for each directory.  \\n\\n```python\\nimport os\\n\\ndirectory = \\\".\\\"  # Target directory\\n\\nfor root, dirs, files in os.walk(directory):\\n    for file in files:\\n        full_path = os.path.join(root, file)\\n        print(full_path)\\n```  \\n\\n\\n#### Using `pathlib` (recursive):  \\n`Path.rglob(\\\"*\\\")` recursively matches all paths. Filter for files with `is_file()`.  \\n\\n```python\\nfrom pathlib import Path\\n\\ndirectory = Path(\\\".\\\")  # Target directory\\n\\nfor file in directory.rglob(\\\"*\\\"):  # Recursively search all subdirectories\\n    if file.is_file():\\n        print(file)  # Print full file path\\n```  \\n\\n\\n### Key Differences:  \\n- **`os` module**:  \\n  - Traditional, works in older Python versions.  \\n  - Requires manual path joining (`os.path.join()`) and checks (`os.path.isfile()`).  \\n\\n- **`pathlib` module**:  \\n  - Modern, object-oriented, and more intuitive.  \\n  - Paths are `Path` objects with built-in methods (e.g., `is_file()`, `rglob()`).  \\n\\n\\n### Example: List files in a **specific directory**  \\nTo target a specific folder (e.g., `\\\"/home/user/documents\\\"` or `\\\"C:\\\\\\\\my_files\\\"`), replace `directory` with the full path:  \\n\\n```python\\n# Using os (non-recursive)\\ndirectory = \\\"/home/user/documents\\\"\\nfor entry in os.listdir(directory):\\n    full_path = os.path.join(directory, entry)\\n    if os.path.isfile(full_path):\\n        print(full_path)\\n\\n# Using pathlib (recursive)\\nfrom pathlib import Path\\ndirectory = Path(\\\"/home/user/documents\\\")\\nfor file in directory.rglob(\\\"*\\\"):\\n    if file.is_file():\\n        print(file)\\n```  \\n\\n\\n### Bonus: Print only filenames (not full paths)  \\nTo print just the filename (not the full path), modify the code:  \\n\\n- For `os` (non-recursive):  \\n  ```python\\n  print(entry)  # Instead of print(full_path)\\n  ```  \\n\\n- For `pathlib` (non-recursive):  \\n  ```python\\n  print(item.name)  # Instead of print(item)\\n  ```  \\n\\n\\nChoose the method that best fits your needs (recursive vs. non-recursive, simplicity vs. compatibility)!\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"reasoning_content\": \"Got it, the user wants to know how to output all files in a directory using Python. Let's think about the different methods. First, the os module, maybe os.listdir, or os.scandir. Also, pathlib in newer Python versions. Let's break it down.\\n\\nFirst, using os.listdir. That function lists all entries (files and directories) in a given path. So you can loop through them and check if they are files. Wait, but maybe the user wants to list all files, including in subdirectories? Or just the top-level? The question says \\\"all files in a directory\\\"â€”maybe top-level, or recursive? Let's cover both.\\n\\nFirst, top-level files (not directories) in a directory. Let's start with os.listdir. So import os, then specify the directory path. Then for each entry, check if it's a file (using os.path.isfile). So code like:\\n\\nimport os\\n\\ndirectory = '.'  # current directory, can be replaced with any path\\nfor entry in os.listdir(directory):\\n    full_path = os.path.join(directory, entry)\\n    if os.path.isfile(full_path):\\n        print(full_path)\\n\\nBut maybe the user wants to include subdirectories recursively. Then os.walk would be better. os.walk traverses directories recursively. So:\\n\\nfor root, dirs, files in os.walk(directory):\\n    for file in files:\\n        print(os.path.join(root, file))\\n\\nAlternatively, using pathlib, which is more object-oriented. For top-level files:\\n\\nfrom pathlib import Path\\n\\ndirectory = Path('.')  # current directory\\nfor file in directory.iterdir():\\n    if file.is_file():\\n        print(file)\\n\\nFor recursive, use rglob('*') or glob('**/*'):\\n\\nfor file in directory.rglob('*'):\\n    if file.is_file():\\n        print(file)\\n\\nWait, rglob('*') would include all files recursively. Or using glob with **, but need to set recursive=True. Let's check: Path('.').glob('**/*') would also work, but rglob is a convenience method.\\n\\nSo let's structure the answer. First, explain the different approaches: listing files in the current directory (non-recursive) and recursively. Then show code examples for each method (os module and pathlib).\\n\\nLet's start with the os module for non-recursive:\\n\\nUsing os.listdir and os.path.isfile:\\n\\nimport os\\n\\n# Define the directory path, e.g., current directory is '.', or a specific path like 'C:/Users/username/Documents'\\ndir_path = '.'  # change to your desired directory\\nfor item in os.listdir(dir_path):\\n    item_path = os.path.join(dir_path, item)\\n    if os.path.isfile(item_path):\\n        print(item_path)\\n\\nThen, for recursive listing with os.walk:\\n\\nimport os\\n\\ndir_path = '.'\\nfor root, dirs, files in os.walk(dir_path):\\n    for file in files:\\n        file_path = os.path.join(root, file)\\n        print(file_path)\\n\\nNow using pathlib (Python 3.4+), which is more modern:\\n\\nFor non-recursive (top-level files):\\n\\nfrom pathlib import Path\\n\\ndir_path = Path('.')  # can be Path('your/directory/path')\\nfor file in dir_path.iterdir():\\n    if file.is_file():\\n        print(file)\\n\\nFor recursive listing:\\n\\nfrom pathlib import Path\\n\\ndir_path = Path('.')\\nfor file in dir_path.rglob('*'):  # rglob('*') includes all files and directories recursively, but we check if it's a file\\n    if file.is_file():\\n        print(file)\\n\\nAlternatively, using glob with recursive=True:\\n\\nfor file in dir_path.glob('**/*'):\\n    if file.is_file():\\n        print(file)\\n\\nBut rglob is simpler.\\n\\nSo summarizing, the methods depend on whether you need recursive listing or not, and whether you prefer the os module or pathlib.\\n\\nAlso, note that os.listdir includes both files and directories, so we need to check with os.path.isfile. Similarly, pathlib's iterdir() gives Path objects, so we check is_file().\\n\\nAnother thing: if the user just wants the filenames (not full paths), they can adjust the code. For example, in the os.listdir example, print(item) instead of item_path, but that would be just the filename, not the full path. So better to use the full path.\\n\\nSo putting it all together, the answer should explain the different methods (non-recursive and recursive) using both os and pathlib, with code examples.\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1761819263,\n",
      "  \"model\": \"doubao-seed-1-6-vision-250815\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 1951,\n",
      "    \"prompt_tokens\": 68,\n",
      "    \"total_tokens\": 2019,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"reasoning_tokens\": 1019\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# gets the API Key from environment variable AZURE_OPENAI_API_KEY\n",
    "endpoint = Endpoint()\n",
    "\n",
    "\n",
    "response = await endpoint.chat_completions_create(\n",
    "            messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How do I output all files in a directory using Python?\",\n",
    "        },\n",
    "    ],\n",
    "        )\n",
    "print(response.to_json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62a9d052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def flatten_dict(d: dict, level: int, parent_key: str = '', sep: str = '.') -> dict:\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, dict) and v and level > 0:\n",
    "            items.extend(flatten_dict(v, level - 1, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7ca4e56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level=0: {'a': 1, 'b': {'c': 2, 'd': {'e': 3}}}\n",
      "level=1: {'a': 1, 'b.c': 2, 'b.d': {'e': 3}}\n",
      "level=2: {'a': 1, 'b.c': 2, 'b.d.e': 3}\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯• flatten_dict å‡½æ•°\n",
    "# å®šä¹‰ä¸€ä¸ªåµŒå¥—å­—å…¸ç”¨äºæµ‹è¯•\n",
    "test_dict = {\n",
    "    'a': 1,\n",
    "    'b': {\n",
    "        'c': 2,\n",
    "        'd': {\n",
    "            'e': 3\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# æµ‹è¯•ä¸åŒçš„ level å€¼\n",
    "print(\"level=0:\", flatten_dict(test_dict, level=0))\n",
    "print(\"level=1:\", flatten_dict(test_dict, level=1))\n",
    "print(\"level=2:\", flatten_dict(test_dict, level=2))"
   ]
  }
 ],
 "metadata": {
  "fileId": "04f97f42-96ae-4c90-a0f2-062dad8613cd",
  "filePath": "/root/repos/peft/BoGuan_YueQu/third_party/infras/ScholarlyInfrastructure/notebooks/04_llm_api.ipynb",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
