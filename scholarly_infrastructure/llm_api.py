"""å¸®åŠ©OPENAI API æ¨ç†æœ‰å…³çš„å‡½æ•°"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../src/notebooks/04_llm_api.ipynb.

# %% auto 0
__all__ = [
    "make_info_df",
    "get_pydantic_version",
    "is_url",
    "is_local_file_path",
    "download_file",
    "local_video_to_base64_uri",
    "separate_think_and_other",
    "extract_code_content",
    "get_env_bool",
    "Endpoint",
    "flatten_dict",
]

# %% ../src/notebooks/04_llm_api.ipynb 4
import pandas as pd


def make_info_df(df, n_samples=2):
    """
    æ„é€ åŒ…å« column_name, dtype å’Œå‰ n_samples è¡Œæ ·æœ¬å€¼çš„è¡¨æ ¼
    """
    info_df = pd.DataFrame({"column_name": df.columns, "dtype": df.dtypes.values})
    # æ·»åŠ å‰ n_samples è¡Œæ ·æœ¬å€¼
    for i in range(n_samples):
        col = f"sample{i + 1}"
        info_df[col] = df.iloc[i].values
    return info_df


# %% ../src/notebooks/04_llm_api.ipynb 5
import pydantic


def get_pydantic_version():
    """
    åˆ¤æ–­å½“å‰ä½¿ç”¨çš„æ˜¯ Pydantic 1 è¿˜æ˜¯ Pydantic 2
    :return: ç‰ˆæœ¬å· 1 æˆ– 2
    """
    try:
        if pydantic.VERSION.startswith("1"):
            return 1
        elif pydantic.VERSION.startswith("2"):
            return 2
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ Pydantic ç‰ˆæœ¬: {pydantic.VERSION}")
    except AttributeError:
        # Pydantic 1 å¯èƒ½æ²¡æœ‰ VERSION å±æ€§ï¼Œé€šè¿‡å…¶ä»–æ–¹å¼åˆ¤æ–­
        try:
            from pydantic.main import ModelMetaclass

            return 1
        except ImportError:
            return 2


# %% ../src/notebooks/04_llm_api.ipynb 7
import re
from urllib.parse import urlparse
import os


def is_url(s: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºURLï¼ˆåŒ…å«http/https/ftp/fileç­‰åè®®ï¼‰"""
    # 1. è¯­æ³•æ ¡éªŒï¼šåè®®å‰ç¼€ + ://ï¼ˆfile:// ä¹Ÿç¬¦åˆï¼‰
    url_pattern = r"^[a-zA-Z][a-zA-Z0-9+.-]*://[^\s]*$"
    if not re.match(url_pattern, s.strip()):
        return False
    # 2. è§£æåè®®ï¼Œç¡®è®¤æ˜¯åˆæ³•URLåè®®
    parsed = urlparse(s)
    valid_schemes = {"http", "https", "ftp", "ftps", "sftp", "ssh", "telnet", "file"}
    return parsed.scheme.lower() in valid_schemes


def is_local_file_path(s: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºæœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼ˆéURLæ ¼å¼ï¼‰"""
    # æ’é™¤URLï¼ˆé¿å…ä¸file://æ··æ·†ï¼‰
    if is_url(s):
        return False
    # æ£€æŸ¥æ˜¯å¦ç¬¦åˆæ“ä½œç³»ç»Ÿçš„æ–‡ä»¶è·¯å¾„æ ¼å¼
    # ç®€åŒ–åˆ¤æ–­ï¼šåŒ…å«è·¯å¾„åˆ†éš”ç¬¦ï¼Œæˆ–ç¬¦åˆç›˜ç¬¦ï¼ˆWindowsï¼‰/æ ¹ç›®å½•ï¼ˆLinux/macOSï¼‰ç‰¹å¾
    s_stripped = s.strip()
    if not s_stripped:
        return False
    # Windowsè·¯å¾„ç‰¹å¾ï¼šç›˜ç¬¦ï¼ˆå¦‚C:ï¼‰+ åæ–œæ æˆ–æ–œæ 
    windows_pattern = r"^[a-zA-Z]:[\\/].*"
    # Linux/macOSè·¯å¾„ç‰¹å¾ï¼šæ ¹ç›®å½•/æˆ–ç›¸å¯¹è·¯å¾„./../
    unix_pattern = r"^(/|\./|\.\./).*"
    # è¿˜å¯ä»¥é€šè¿‡å°è¯•è§£æè·¯å¾„æ˜¯å¦åˆæ³•è¿›ä¸€æ­¥éªŒè¯ï¼ˆå¯é€‰ï¼‰
    try:
        # å°è¯•è§„èŒƒåŒ–è·¯å¾„ï¼ˆè‹¥æŠ¥é”™åˆ™ä¸æ˜¯æœ‰æ•ˆè·¯å¾„ï¼‰
        os.path.normpath(s_stripped)
        return (
            re.match(windows_pattern, s_stripped) is not None
            or re.match(unix_pattern, s_stripped) is not None
        )
    except:
        return False


# %% ../src/notebooks/04_llm_api.ipynb 10
import aiohttp
import aiofiles
import tempfile
from pathlib import Path
from typing import Optional, Union
from urllib.parse import urlparse, unquote


async def download_file(
    video_url: str, verbose: bool = False, target: Optional[Union[str, Path]] = None
) -> Optional[str]:
    """
    å¼‚æ­¥ä¸‹è½½æ–‡ä»¶ã€‚æ”¯æŒæŒ‡å®šè·¯å¾„ã€è‡ªåŠ¨åˆ›å»ºç›®å½•åŠéé˜»å¡å†™å…¥ã€‚

    :param video_url: æ–‡ä»¶URL
    :param verbose: æ˜¯å¦æ‰“å°è¯¦ç»†æ—¥å¿— (ä¿æŒåœ¨ç¬¬äºŒä¸ªå‚æ•°ä»¥å…¼å®¹æ—§ä»£ç )
    :param target: ç›®æ ‡è·¯å¾„ (å¯ä»¥æ˜¯ç›®å½•æˆ–å®Œæ•´æ–‡ä»¶è·¯å¾„)ã€‚è‹¥ä¸ºNoneï¼Œåˆ™ç”Ÿæˆä¸´æ—¶æ–‡ä»¶ã€‚
    :return: æ–‡ä»¶çš„ç»å¯¹è·¯å¾„å­—ç¬¦ä¸² (ä¸‹è½½å¤±è´¥è¿”å›None)
    """
    save_path: Path = Path()  # åˆå§‹åŒ–

    try:
        # --- 1. è§£ææ–‡ä»¶å ---
        # ä½¿ç”¨ urllib è§£æï¼Œæ¯” split('/') æ›´å®‰å…¨ï¼Œèƒ½å¤„ç† URL ç¼–ç 
        parsed_url = urlparse(video_url)
        # unquote å°† %20 ç­‰è½¬ä¸ºæ­£å¸¸å­—ç¬¦ï¼ŒPath(..).name è·å–æ–‡ä»¶å
        url_filename = Path(unquote(parsed_url.path)).name
        if not url_filename:
            url_filename = "downloaded_file.tmp"  # å…œåº•æ–‡ä»¶å

        # --- 2. ç¡®å®šä¿å­˜è·¯å¾„ (Pathlib é€»è¾‘) ---
        if target:
            target_path = Path(target)

            # å¦‚æœç›®æ ‡æ˜¯ä¸€ä¸ªå·²å­˜åœ¨çš„ç›®å½•ï¼Œåˆ™æ‹¼æ¥åˆ°è¯¥ç›®å½•ä¸‹
            if target_path.is_dir():
                save_path = target_path / url_filename
            else:
                # å¦åˆ™è§†ä¸ºå®Œæ•´æ–‡ä»¶è·¯å¾„
                save_path = target_path
                # ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨ (ç›¸å½“äº mkdir -p)
                save_path.parent.mkdir(parents=True, exist_ok=True)
        else:
            # æœªæŒ‡å®šè·¯å¾„ï¼Œä½¿ç”¨ç³»ç»Ÿä¸´æ—¶æ–‡ä»¶
            suffix = Path(url_filename).suffix
            # åˆ›å»ºä¸€ä¸ªä¸´æ—¶æ–‡ä»¶æ¥å ä½å¹¶è·å–è·¯å¾„ (delete=False é˜²æ­¢å…³é—­å³åˆ )
            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                save_path = Path(tmp.name)
            # æ­¤æ—¶æ–‡ä»¶å·²å­˜åœ¨ï¼ˆç©ºæ–‡ä»¶ï¼‰ï¼Œæˆ‘ä»¬åªéœ€è·å–è·¯å¾„ï¼Œç¨åç”¨ aiofiles è¦†ç›–å†™å…¥

        if verbose:
            print(f"â¬‡ï¸  å¼€å§‹ä¸‹è½½: {video_url}")
            print(f"ğŸ“‚ ç›®æ ‡è·¯å¾„: {save_path}")

        # --- 3. å¼‚æ­¥ä¸‹è½½ä¸å†™å…¥ (aiofiles) ---
        timeout = aiohttp.ClientTimeout(total=600)
        async with aiohttp.ClientSession() as session:
            async with session.get(video_url, timeout=timeout) as response:
                if response.status != 200:
                    if verbose:
                        print(f"âŒ ä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status}")
                    # æ¸…ç†å ä½çš„ç©ºæ–‡ä»¶
                    if save_path.exists():
                        save_path.unlink()
                    return None

                # ä½¿ç”¨ aiofiles è¿›è¡Œå¼‚æ­¥å†™å…¥ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                async with aiofiles.open(save_path, "wb") as f:
                    async for chunk in response.content.iter_chunked(
                        1024 * 1024
                    ):  # 1MB å—
                        await f.write(chunk)

        if verbose:
            print(f"âœ… ä¸‹è½½å®Œæˆ: {save_path}")

        # è¿”å›ç»å¯¹è·¯å¾„å­—ç¬¦ä¸²ï¼Œæ–¹ä¾¿å¤–éƒ¨è°ƒç”¨
        return str(save_path.absolute())

    except Exception as e:
        if verbose:
            print(f"âŒ ä¸‹è½½å‡ºé”™: {e}")
        # å‘ç”Ÿå¼‚å¸¸æ—¶çš„æ¸…ç†å·¥ä½œ
        if save_path and save_path.exists():
            try:
                save_path.unlink()  # pathlib çš„åˆ é™¤æ–‡ä»¶æ–¹æ³•
            except OSError:
                pass
        return None


# %% ../src/notebooks/04_llm_api.ipynb 13
import base64
import os
import asyncio

try:
    import aiofiles
except ImportError:
    print("è¯·å…ˆå®‰è£… 'aiofiles' åº“: !pip install aiofiles")


async def local_video_to_base64_uri(file_path: str) -> str:
    """
    å¼‚æ­¥åœ°å°†æœ¬åœ°è§†é¢‘æ–‡ä»¶è½¬æ¢ä¸º Base64 ç¼–ç çš„æ•°æ® URIã€‚

    æ ¼å¼éµå¾ª: data:video/<è§†é¢‘æ ¼å¼>;base64,<Base64ç¼–ç >ï¼Œå…¶ä¸­ï¼Œ
    è§†é¢‘æ ¼å¼: æ”¯æŒ mp4, avi, movã€‚
    Base64ç¼–ç : è§†é¢‘æ–‡ä»¶çš„ Base64 ç¼–ç ã€‚

    Args:
        file_path: æœ¬åœ°è§†é¢‘æ–‡ä»¶çš„è·¯å¾„ã€‚

    Returns:
        ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ŒåŒ…å«äº†è§†é¢‘çš„ Base64 ç¼–ç æ•°æ® URIã€‚

    Raises:
        ValueError: å¦‚æœè§†é¢‘æ ¼å¼ä¸æ˜¯ 'mp4', 'avi', æˆ– 'mov' ä¹‹ä¸€ã€‚
        FileNotFoundError: å¦‚æœåœ¨ file_path æŒ‡å®šçš„è·¯å¾„ä¸‹æ‰¾ä¸åˆ°æ–‡ä»¶ã€‚
    """
    supported_formats = {"mp4", "avi", "mov"}

    # ä»è·¯å¾„ä¸­è·å–æ–‡ä»¶æ‰©å±•åä½œä¸ºè§†é¢‘æ ¼å¼
    file_extension = file_path.split(".")[-1].lower()

    if file_extension not in supported_formats:
        raise ValueError(
            f"ä¸æ”¯æŒçš„è§†é¢‘æ ¼å¼: '{file_extension}'ã€‚æ”¯æŒçš„æ ¼å¼ä¸º: {', '.join(supported_formats)}"
        )

    if not os.path.exists(file_path):
        raise FileNotFoundError(f"æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")

    # å¼‚æ­¥è¯»å–æ–‡ä»¶
    async with aiofiles.open(file_path, "rb") as video_file:
        video_bytes = await video_file.read()

    # è¿›è¡Œ Base64 ç¼–ç 
    base64_encoded_video = base64.b64encode(video_bytes).decode("utf-8")

    # æ‹¼æ¥æˆæœ€ç»ˆçš„ Data URI å­—ç¬¦ä¸²
    return f"data:video/{file_extension};base64,{base64_encoded_video}"


# %% ../src/notebooks/04_llm_api.ipynb 15
import re
from typing import Optional, Tuple


def separate_think_and_other(text: str) -> Tuple[Optional[str], str]:
    """
    ä»æ–‡æœ¬ä¸­åˆ†ç¦» <think> æ ‡ç­¾å†…å®¹å’Œå…¶ä½™å†…å®¹ã€‚

    Args:
        text: åŒ…å«æˆ–ä¸åŒ…å« <think> æ ‡ç­¾çš„åŸå§‹å­—ç¬¦ä¸²ã€‚

    Returns:
        ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«ä¸¤éƒ¨åˆ†ï¼š
        - ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯æ‰€æœ‰ <think> æ ‡ç­¾å†…å†…å®¹çš„åˆå¹¶å­—ç¬¦ä¸²ï¼ˆä»¥æ¢è¡Œç¬¦åˆ†éš”ï¼‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä¸º Noneã€‚
        - ç¬¬äºŒä¸ªå…ƒç´ æ˜¯å»é™¤ <think> æ ‡ç­¾åå‰©ä½™å†…å®¹çš„åˆå¹¶å­—ç¬¦ä¸²ã€‚
    """
    # ä½¿ç”¨ re.findall æ‰¾åˆ°æ‰€æœ‰ <think> æ ‡ç­¾çš„å†…å®¹
    # re.DOTALL æ ‡å¿—è®© '.' å¯ä»¥åŒ¹é…åŒ…æ‹¬æ¢è¡Œç¬¦åœ¨å†…çš„ä»»ä½•å­—ç¬¦
    think_parts = re.findall(r"<think>(.*?)</think>", text, re.DOTALL)

    if think_parts:
        # åˆå¹¶æ‰€æœ‰ <think> æ ‡ç­¾å†…çš„å†…å®¹ï¼Œä½¿ç”¨æ¢è¡Œç¬¦åˆ†éš”
        think_content = "\n".join(part.strip() for part in think_parts)
    else:
        think_content = None

    # ä½¿ç”¨ re.split æ¥è·å– <think> æ ‡ç­¾å¤–çš„å†…å®¹
    other_parts = re.split(r"<think>.*?</think>", text, flags=re.DOTALL)
    # åˆå¹¶æ‰€æœ‰æ ‡ç­¾å¤–çš„å†…å®¹ï¼Œå¹¶æ¸…ç†é¦–å°¾åŠä¸­é—´å¤šä½™çš„ç©ºç™½
    other_content = "\n".join(part.strip() for part in other_parts if part.strip())

    return think_content, other_content


# %% ../src/notebooks/04_llm_api.ipynb 17
import re
from typing import Optional


def extract_code_content(text: str, target_lang: Optional[str] = None) -> str:
    """
    ä»å­—ç¬¦ä¸²ä¸­æå–ç¬¬ä¸€ä¸ª Markdown ä»£ç å—çš„å†…å®¹ã€‚
    å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œåˆ™ç›´æ¥è¿”å›åŸæ–‡æœ¬ã€‚
    """
    if target_lang is None:
        pattern = re.compile(r"```(?:[a-zA-Z0-9_+-]*)\n(.*?)```", re.DOTALL)
    else:
        pattern = re.compile(rf"```{target_lang}\n(.*?)```", re.DOTALL)
    match = pattern.search(text)
    if match:
        return match.group(1).strip()
    else:
        return text.strip()


# %% ../src/notebooks/04_llm_api.ipynb 19
import os
import asyncio
import time
from openai import AsyncOpenAI, APIError, AsyncAzureOpenAI, OpenAI, AzureOpenAI
from typing import Optional, Tuple
import os


def get_env_bool(env_var, default=False):
    env_val = os.getenv(env_var)
    if env_val is None:
        return default
    true_values = ("true", "1", "yes", "on", "y", "t")
    return env_val.strip().lower() in true_values


class Endpoint:
    def __init__(
        self,
        base_url: Optional[str] = None,
        ip: Optional[str] = None,
        port: Optional[int] = None,
        api_key: Optional[str] = None,
        model_name_or_path: Optional[str] = None,
        use_azure: Optional[bool] = None,  # https://github.com/openai/openai-python
        api_version: Optional[str] = None,
    ):
        self.model_name_or_path = (
            model_name_or_path or os.getenv("OPENAI_MODEL") or "gemini-2.5-flash"
        )

        # Handle IPv6 addresses by wrapping them in brackets for URL compatibility
        if ip and ":" in ip:
            ip = f"[{ip}]"
        if ip and port:
            self.base_url = f"http://{ip}:{port}/v1"
        else:
            self.base_url = (
                base_url
                or os.getenv("OPENAI_BASE_URL")
                or os.getenv("AZURE_OPENAI_ENDPOINT")
            )
        api_key = (
            api_key
            or os.getenv("OPENAI_API_KEY")
            or os.getenv("AZURE_OPENAI_API_KEY")
            or "not-needed"
        )
        api_version = (
            api_version
            or os.getenv("OPENAI_API_VERSION")
            or os.getenv("AZURE_OPENAI_API_VERSION")
            or "2024-03-01-preview"
        )
        use_azure = use_azure or get_env_bool("OPENAI_USE_AZURE")
        if use_azure:
            self.async_client = AsyncAzureOpenAI(
                azure_endpoint=self.base_url,
                api_key=api_key,
                api_version=api_version,  # type: ignore
            )
            self.client = AzureOpenAI(
                azure_endpoint=self.base_url,
                api_key=api_key,
                api_version=api_version,  # type: ignore
            )
        else:
            self.async_client = AsyncOpenAI(base_url=self.base_url, api_key=api_key)
            self.client = OpenAI(base_url=self.base_url, api_key=api_key)

    def __repr__(self) -> str:
        return (
            f"Endpoint(base_url={self.base_url!r}, "
            f"model_name_or_path={self.model_name_or_path!r}, "
            f"use_azure={self.async_client.__class__.__name__.startswith('AsyncAzureOpenAI')})"
        )

    async def chat_completions_create(self, **kwargs):
        return await self.async_client.chat.completions.create(
            model=self.model_name_or_path, **kwargs
        )

    def chat_completions_create_sync(self, **kwargs):
        return self.client.chat.completions.create(
            model=self.model_name_or_path, **kwargs
        )


# %% ../src/notebooks/04_llm_api.ipynb 21
def flatten_dict(d: dict, level: int, parent_key: str = "", sep: str = ".") -> dict:
    items = []
    for k, v in d.items():
        new_key = parent_key + sep + k if parent_key else k
        if isinstance(v, dict) and v and level > 0:
            items.extend(flatten_dict(v, level - 1, new_key, sep=sep).items())
        else:
            items.append((new_key, v))
    return dict(items)
